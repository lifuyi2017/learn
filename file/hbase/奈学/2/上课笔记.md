[TOC]

# 上课须知

课程主题：HBase 分布式数据库 第二次课
上课时间：2020-09-14 20:00 - 23:00
课件休息：21:30 左右 休息10分钟
课前签到：如果能听见音乐，能看到画面，请在直播间扣 666 

其他操作：上次课程中的技术疑问！



# 上次课程总结

## HBase的架构设计

需求：确保在海量数据中，低延时的随机读写

```
1、内存 + 磁盘
2、内存数据良好的数据结构  ConcurentSkipListMap
3、磁盘数据 + 布隆索引   mapreduce的shuffle和HBase的底层数据文件的组织（）
4、范围分区 + 排序    二分查询 + 跳表
5、跳表Topo结构    第一层：user table， 第二层：meta table   第三层： root table
			hbase-1.x  hbase-2.x 么有 .meta.  -root-  ， hbase:meta 
			namespace: database  hbase
			table: meta
			hbase-1.x以前，默认每个region的最大大小是：128M
			hbase-1.x以后：默认每个region的最大大小是10G，
6、读缓存 + 写缓存   
			mapreduce shuffle  100M  缓冲区
			kafka的源码：两个写内存
```

需求：确保在分布式架构中，保证数据的安全

```
1、内存 + 磁盘  ----> 提高效率，保证安全
2、WAL机制  -----> 保证安全
```



## HBase的表逻辑模型

mysql excel  二维表

hbase  四维表

kylin 多维分析引擎 OLAP  cube 

![image-20200914195956248](D:\大数据架构师NDE一期课程资料\奈学NDE一期--day23（09.14）--分布式列式NoSQL数据库HBase--架构原理和源码分析1\asset\HBase表的逻辑模型.png)



## HBase

```
hmaster		主节点，依赖于zookeper实现ha
hregionserver    管理region
client		负责发起请求的：能缓存之前已经查询得到的regioin的位置
zookeeper     帮助hbase实现一些服务协调
```

```
rowkey
column family
qualifier 
timestamp
value
```

```
table    
region   表中个一段rowkey范围中的数据， 都是按照rowkey进行数据排序的
store    如果这张表有多个列簇，那么就会生成多个store
memstore  内存数据
storefile  磁盘文件
```

```
flush   memstore的数据刷出来，形成磁盘文件
split    当一个region变大的时候（一定的标准：10G），就会一分为二。 分出来的两个regioin也都是有序
compact   当storefile达到一个个数的时候，就会触发 compact操作：多个HFile合并成一个
```



## HBase Java API

```
HBaseConfiguration  Connection  ConnectionFactory
Admin  HTable
HTableDescriptor   ColumnFamilyDescriptor   
Put Delete Get Scan
ResultScanner  Result   Cell/KeyValue
```



# 课程大纲

前五个知识：原理和架构设计相关

后两个知识：源码分析



## 架构设计和工作原理

HDFS的元数据：

```
1、目录结构树
2、文件和数据块之间的映射关系
3、数据块和多个副本所在主机之间的映射关系
```

前两个是存储在 内存 和 磁盘

这三个，在内存中，都有！ 区别：磁盘元数据中，是没有存储  第三种类型的元数据



HBase 的元数据：Master

```
1、表结构信息
2、表的region分布信息
```



总结这三种主从架构：

```  
1、单主 多从  单节点宕机，整个集群不可用  HDFS
2、单主 多从  单节点宕机，整个集群部分功能不可用 HBase
3、多主 多从  主节点是一个集群，从节点也是一个集群，主节点集群用来管理从节点集群，多主集群中，也同时只能有一个角色用来做管理，通过选举产生。优势：没有单点故障，也不依赖于任何组件： doris 
```

HDFS:  ZooKeeper    

HBase:  HDFS   ZooKeeper

Kylin:   HDFS,  HBase，ZooKeeper



clickhouse: 不依赖于任何组件。单独生存的。

doris ： 也不依赖于任何组件。



kafka: zookeeper 

不是 broker级别的主从架构，但是每个 分区之间， 有leader 和 follower 之分



比如：往hbase一张表中，插入100T的数据；

```
问题：10W 都是在数据插入不过程中，不停的split分裂出来的。
优化方案： 预分区 建表的时候，估计一下：假设大概有10W个region： 12W  15W 
```



HFile中的每个keyvalue对象的数据结构分成10段，其中有一个叫做： KeyType

有两个值：Put Delete  插入 删除

HBase如何做删除？ 所有的增删改都是 append， 真正的delete生效时间，是在HFile 合并的时候。当然在内存中删除是即时的。



休息十分钟：22:00 开始！



## 建表设计高级操作

表设计

```
create "table", "cf1", "cf2", "cf3"
create "table", {NAME => "CF1", VERSIONS => 3}. {NAME => "CF2", TTL => 29349323}

表名  
	没有太多要求，见名知义，符合企业规范
列簇的定义
	列簇的名称的长度：列簇的长度，最好就是一个子字母  my_best_frirend 
	列簇的个数：最好就是一个，标准：具有IO相关性的列，都组织在一个列簇中。 最多两个
	 		create "stduent", "base_info", "score_info"
	 		name  age  address  个人基本信息
	 		math  chinese, algorithm 
	列的属性的定义
		NAME => 'info', 
		VERSIONS => '1',    这个列簇中的，key的值最多保留多少个版本  k1-v1  k1-v2
		EVICT_BLOCKS_ON_CLOSE => 'false', 
		NEW_VERSION_BEHAVIOR => 'false', 
		KEEP_DELETED_CELLS => 'FALSE', 
		CACHE_DATA_ON_WRITE => 'false', 
		DATA_BLOCK_ENCODING => 'NONE', 
		TTL => 'FOREVER',    数据的生命周期：永久
		MIN_VERSIONS => '0', 
		REPLICATION_SCOPE => '0', 
		BLOOMFILTER => 'ROW',      三种取值：ROW,  ROWCOL, NONE 
		CACHE_INDEX_ON_WRITE => 'false', 
		IN_MEMORY => 'false',    我们可以决定一个region的数据是否都放在内存中
		CACHE_BLOOMS_ON_WRITE => 'false', 
		PREFETCH_BLOCKS_ON_OPEN => 'false', 
		COMPRESSION => 'NONE',    压缩（压缩率  压缩解压缩速率）
		BLOCKCACHE => 'true',    读缓存
		BLOCKSIZE =>'65536'}    blocksize = 64kb
```

在hbase中，表可以停用和启用。如果要删除表，必须要先停用

dissable_all  enable_all 支持正则

```
布隆过滤器：数据结构
核心概念：一个非常长的位数组+多个hash函数
作用：判断一个某个元素在不在布隆里面
核心操作： put contain

使用：bloom.contains(key)
```

两种优化

```
1、预分区
	在要进行大批量数据插入的时候，可以进行提前预分区，防止在插入过程形成大量的split操作
2、bulkload
	put 单条插入
	bulkload 批量插入   table.put(puts)
		正常数据进行插入的时候，都要进行先写操作日志，再写内存，时不时的触发flush和compact和split
		不使用这种插入模式，而是通过mapreduce程序直接生成 HFile, 直接导入到hbase表中的。
		但是优缺点：就是因为没有日志，所以如果数据丢失，就没有找回的可能
```

rowkey设计

```
三原则：
1、长度原则， 不能太长，甚至最好就是一个 字母
2、唯一原则   同一张表的所有rowkey肯定是唯一的
3、散列原则   如果有大量数据要插入hbase表，记得让这些数据尽量分散均匀。
```

总结：一张hbase表拆分成多个region, 我们的期望：每个region的负载是一样的

```
体现在两个方面：
1、如果是扫描非常少量的数据，尽量让这些少量的数据在一个region里面
   region的startkey和rowkey时候split自己决定的。保证这些数据要么是同一个rowkey要么是相邻的rowkey
2、如果你scan大量数据，那就不要让一个region来处理你的请求，应该让多个region来处理你的请求
```

hbase表怎么防止数据倾斜：

```
1、加盐
	一本小说中，的单词，必然会有些很多，有些很少。，加随机前缀即可
2、hash
	既能分散，而且也能让具有相同特征的值，存储在一起，相对于范围分区来说的。
3、反转
	13522334455  13522556688 13566998855  12211445566
	55443322135  22556688135 88551356699
4、时间戳反转
	2020-11-09
	2020-11-10
	2020-11-11
	2020-11-12
```







## 过滤器

到底按照什么规则来过滤数据？

三个要点：

```
比较运算符：CompareOp
	>
	<
	>= 
	<=
	= 
	!= 
	NO_OP 取反
比较器：Comparator 
	前缀
	是否包含某个子字符串
	正则
过滤器：Filter
	RowkeyFilter
	FamilyFilter
	QualifierFilter
搭配使用原则：Filter filter = new XXXXFilter(xxxxComparable, CompareOp.xxxx)
```

两种使用方式：

```
shell使用：
	scan 't1', {ROWPREFIXFILTER => 'row2', FILTER => "
    (QualifierFilter (>=, 'binary:xyz')) AND (TimestampsFilter ( 123, 456))"}

javaapi使用：
	Scan scan  = new Scan()
	scan.setFilter(filter)
	table.getScanner(scan);    范围扫描，带过滤器
```

一个特殊过滤器：

```;
分区过滤器
	1、hbase中的一条数据：一个rowkey
	2、PageFilter  
		Scan scan  = new Scan()
		PageFitler pageFilter = new PageFilter(3);      select ..... limit 10,5;
		scan.setStartRow(startRow)
		scan.setFilter(pageFilter)
		table.getScanner(scan);
```

分页；pageIndex  pageNumber





## 布隆过滤器



## 协处理器Coprocessor

协处理器：Coprocessor

两个种类“

```
1、observer  触发器
2、endpoint  存储过程
```

hook  钩子

AOP

Iterpreter



```
HBase + ES 构建二级索引
```



## HMaster启动流程分析



## HRegionServer启动流程分析





# 总结